<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Utop&#39;s Blog</title>
    <link>https://www.ffutop.com/</link>
    <description>Recent content on Utop&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cmn-Hans-CN</language>
    <lastBuildDate>Sat, 11 Apr 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://www.ffutop.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>HTTP Large Header Fields Problem</title>
      <link>https://www.ffutop.com/posts/2020-04-11-large-http-header/</link>
      <pubDate>Sat, 11 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.ffutop.com/posts/2020-04-11-large-http-header/</guid>
      <description>&lt;p&gt;&lt;em&gt;首次遇到请求头过大的问题，做个记录。特别是在本次处理陷入了误区，做了太多无谓的猜测&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;请求头过大导致响应错误码 400 (Bad Request)、414 (URI Too Long)、431 (Request Header Fields Too Large) 的情况不多，不过原因和解决方案都是比较清晰的。客户端请求的请求头过大导致超出了服务器支持的缓冲区。如果客户端可控，控制请求头的大小；否则，适当调大服务器配置的缓冲区大小。&lt;/p&gt;
&lt;p&gt;最近生产上碰到了这个问题，颇费了一番功夫。接手问题时得到了几个错误的信息，干扰到了处理的全过程。甚至为此去重读了 NGINX Directive &lt;code&gt;client_header_buffer_size&lt;/code&gt; 和 &lt;code&gt;large_client_header_buffers&lt;/code&gt; 在 1.8.1 版本的实现。&lt;/p&gt;
&lt;p&gt;最原始的问题是：NGINX 接收到了大请求头(4.5k)的请求，最终响应了错误码 400 Bad Request 。&lt;/p&gt;
&lt;p&gt;真实的背景因素包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;请求链路 NGINX -&amp;gt; k8s nginx ingress -&amp;gt; k8s pods (Tomcat)&lt;/li&gt;
&lt;li&gt;NGINX &lt;code&gt;large_client_header_buffers&lt;/code&gt; 使用了默认配置 &lt;code&gt;4 8k&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;Tomcat maxHttpHeaderSize 使用了默认配置 (default 8192)&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Idempotent Pattern</title>
      <link>https://www.ffutop.com/posts/2020-03-26-idempotent/</link>
      <pubDate>Thu, 26 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.ffutop.com/posts/2020-03-26-idempotent/</guid>
      <description>&lt;p&gt;&lt;!-- raw HTML omitted --&gt;“同样是 KV-Server ，为什么基于 Raft Algorithm 的 KV-Server 需要对客户端操作实现幂等，而 Redis 却不需要？” 此前在实现基于 Raft 的容错 Key/Value Service 时，为了能够实现幂等的 &lt;code&gt;Put(key, value)&lt;/code&gt;、&lt;code&gt;Append(key, arg)&lt;/code&gt; 操作，可谓是费尽心思。但同为提供键值服务的 Redis ，怎么从来没见被要求幂等呢？&lt;/p&gt;
&lt;p&gt;基于这个问题，本篇将整理并总结个人的结论。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>基于DNS的数据库切换·事故</title>
      <link>https://www.ffutop.com/posts/2020-02-28-db-transfer-based-on-dns/</link>
      <pubDate>Fri, 28 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.ffutop.com/posts/2020-02-28-db-transfer-based-on-dns/</guid>
      <description>&lt;p&gt;我们生产环境上所有的应用都是通过域名来访问 MySQL、Redis 等基础服务。按说域名相较于 IP，凭空多了个 DNS 解析动作，是一个劣化的方案。但好处在于，一旦需要切换基础服务，将带来巨大的利好。可是，任何忽视DNS Record TTL的切换方案，都将伴随着巨大的风险。甚至，成为否定该利好的佐证。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>分布式共识·Raft Algorithm</title>
      <link>https://www.ffutop.com/posts/2020-02-17-raft/</link>
      <pubDate>Mon, 17 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.ffutop.com/posts/2020-02-17-raft/</guid>
      <description>&lt;h2 id=&#34;分布式系统与共识&#34;&gt;分布式系统与共识&lt;/h2&gt;
&lt;p&gt;分布式系统是一组透过网络相互连接通信与传递信息的计算机，协同来完成一件任务的系统。任务可能是大规模计算，可能是冗余存储。按此分类，又有分布式计算系统和分布式存储系统。&lt;/p&gt;
&lt;p&gt;典型的分布式计算系统/框架有 MapReduce、Spark；分布式存储系统有 GFS 等。虽然有此划分，但分布式计算几乎必然地涉及到存储的需求。存储为计算提供支持，计算促进存储的发展。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://img.ffutop.com/3885C079-B4ED-4B0E-AD86-60AB8D4D4792.png&#34; alt=&#34;分布式系统分类&#34;&gt;&lt;/p&gt;
&lt;p&gt;计算是无状态的，存储是有状态的。在分布式的存储下，为了让计算机各自维护的状态协商达成一致，就必然地需要共识算法的支持。Wait a minute. 计算机间的协商需要共识算法？&lt;/p&gt;
&lt;p&gt;计算机间的协作可以划分为中心化与去中心化两大类。中心化的方案自然是有一个权威的 Master 来协调所有的计算机的任务，但前提是这个 Master 必须可靠，即依赖一个单点就必须要对它的可用性进行担保；去中心化的方案，计算机间都是平等的，如何就一个问题达成共识，就是面对的核心问题。&lt;/p&gt;
&lt;blockquote&gt;
&lt;h3 id=&#34;共识与一致性&#34;&gt;共识与一致性&lt;/h3&gt;
&lt;p&gt;共识(Consensus)：机器之间就一个值/命令等达成共同的认识，一般是面向输入，处理并维护这个值（状态）&lt;/p&gt;
&lt;p&gt;一致性(Consistency)：一致性表述为机器对外提供服务时的表现。向机器 A 或机器 B 读取同一数据，两者的返回值是相同的。当然，也有不同的弱化版本，允许一些特定条件下的不一致&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在 2014 年之前，Paxos [1] 几乎是解决共识问题的唯一选择。但难懂是一个致命的问题，并且难以工程化也是重大的缺陷。Raft 的出现无疑是一道曙光，熟读，实践，豁然开朗。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Goroutine 与调度</title>
      <link>https://www.ffutop.com/posts/2020-01-27-go-routine/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.ffutop.com/posts/2020-01-27-go-routine/</guid>
      <description>&lt;p&gt;虽然我们在日常沟通中把 Goroutine 和线程、协程之类的执行流概念混杂着沟通，但 Go 语言一直坚持 &amp;ldquo;Goroutine&amp;rdquo;。 宣称这一名词的产生是由于线程、协程、进程等无法准确表达其概念。本篇将就这一声明进行探究，Goroutine 与线程、协程究竟有何不同。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Calico 网络通信解析</title>
      <link>https://www.ffutop.com/posts/2019-12-24-how-calico-works/</link>
      <pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.ffutop.com/posts/2019-12-24-how-calico-works/</guid>
      <description>&lt;p&gt;在 Kubernetes 集群中，Calico 区别于 Flannel 的最显著特征，就是其宣称可以不借助隧道技术，是建立在纯三层协议上的解决方案。也就是说，Calico 通过建立一些路由信息，就构建了单节点/多节点网络命名空间隔离下的通信网络。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HTTPS 安全通讯如何上演？</title>
      <link>https://www.ffutop.com/posts/2019-12-14-https/</link>
      <pubDate>Sat, 14 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.ffutop.com/posts/2019-12-14-https/</guid>
      <description>&lt;p&gt;最初的 HTTP 以明文传输方式运行在 Internet 上。随着越来越多安全敏感型应用的出现，HTTP over TCP 无法提供足够的安全性保障。SSL 及其继任者 TLS 在这样的背景下产生，提供面向信道的安全性。本文着力于展现 HTTP over TLS (即 HTTPS)的工作方式，以及与此密切相关的数字证书、对称/非对称加密等，但不涉及密码学相关实现及 SSL/TLS 的安全性证明。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GroovyClassLoader 引发的 FullGC</title>
      <link>https://www.ffutop.com/posts/2019-11-07-groovyclassloader-fullgc/</link>
      <pubDate>Wed, 06 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.ffutop.com/posts/2019-11-07-groovyclassloader-fullgc/</guid>
      <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;近日，一个线上应用的存活探针频繁报警。几分钟内 Full GC 次数暴涨上百次，&lt;strong&gt;stop the world&lt;/strong&gt; :&amp;lt; 从 &lt;code&gt;gc.log&lt;/code&gt; 中，看到的原因是触及了 &lt;code&gt;Metaspace&lt;/code&gt; 的阈值，进而引发了 FGC。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-plain&#34; data-lang=&#34;plain&#34;&gt;2019-11-05T14:31:38.880+0800: 504600.716: [Full GC (Metadata GC Threshold) 2019-11-05T14:31:38.880+0800: 504600.716: [CMS2019-11-05T14:31:39.364+0800: 504601.201: [CMS-concurrent-mark: 0.485/0.488 secs] [Times: user=0.48 sys=0.00, real=0.49 secs]
 (concurrent mode failure): 266828K-&amp;gt;266865K(873856K), 1.3752377 secs] 267430K-&amp;gt;266865K(1267072K), [Metaspace: 204152K-&amp;gt;204152K(1267712K)], 1.3757441 secs] [Times: user=1.36 sys=0.00, real=1.38 secs]
2019-11-05T14:31:40.256+0800: 504602.092: [Full GC (Last ditch collection) 2019-11-05T14:31:40.256+0800: 504602.092: [CMS: 266865K-&amp;gt;266841K(873856K), 0.8590901 secs] 266865K-&amp;gt;266841K(1267072K), [Metaspace: 204152K-&amp;gt;204152K(1267712K)], 0.8595047 secs] [Times: user=0.86 sys=0.00, real=0.86 secs]
2019-11-05T14:31:41.117+0800: 504602.953: [Full GC (Metadata GC Threshold) 2019-11-05T14:31:41.117+0800: 504602.953: [CMS: 266841K-&amp;gt;266816K(873856K), 0.9109948 secs] 267218K-&amp;gt;266816K(1267072K), [Metaspace: 204153K-&amp;gt;204153K(1267712K)], 0.9114975 secs] [Times: user=0.91 sys=0.00, real=0.91 secs]
2019-11-05T14:31:42.028+0800: 504603.865: [Full GC (Last ditch collection) 2019-11-05T14:31:42.028+0800: 504603.865: [CMS: 266816K-&amp;gt;266769K(873856K), 1.0351283 secs] 266816K-&amp;gt;266769K(1267072K), [Metaspace: 204153K-&amp;gt;204153K(1267712K)], 1.0355630 secs] [Times: user=0.92 sys=0.00, real=1.04 secs]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;FGC 前后，&lt;code&gt;Metaspace&lt;/code&gt; 占用的内存没有得到任何释放。&lt;em&gt;[Metaspace: 204153K-&amp;gt;204153K(1267712K)]&lt;/em&gt; 。这也就是反复 FGC 的原因。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>随机数生成器拖慢 Tomcat 启动速度</title>
      <link>https://www.ffutop.com/posts/2019-10-17-random/</link>
      <pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.ffutop.com/posts/2019-10-17-random/</guid>
      <description>&lt;p&gt;最近频繁发布应用，Tomcat 的启动效率竟然莫名其妙地出现了断崖式下降。正常 30 秒左右启动的应用，硬生生花了将近 7 分钟。通过检索日志发现了一些有意思的内容。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-plain&#34; data-lang=&#34;plain&#34;&gt;16-Oct-2019 14:23:31.999 WARNING [localhost-startStop-1] org.apache.catalina.util.SessionIdGeneratorBase.createSecureRandom Creation of SecureRandom instance for session ID generation using [SHA1PRNG] took [386,690] milliseconds.
...
16-Oct-2019 14:23:33.111 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 410675 ms
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;创建 &lt;code&gt;SecureRandom&lt;/code&gt; 竟然花了 6 分多钟，占了整个启动时间的 94% 。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>理解 Linux Kernel (14) - cBPF</title>
      <link>https://www.ffutop.com/posts/2019-10-12-bpf/</link>
      <pubDate>Sat, 12 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.ffutop.com/posts/2019-10-12-bpf/</guid>
      <description>&lt;p&gt;BPF (Berkeley Packet Filter) 相比于其他包过滤技术，最重要的突破就是实现了一种全新的内核态/用户态隔离下的内核数据过滤方案。自由定制的网络监控程序，总是作为用户级程序运行，为完成监控/过滤网络数据包的任务，必然地会涉及到内核空间/用户空间的拷贝。而众所周知的，内核空间/用户空间的拷贝代价极大，特别在大流量的情况下。BPF 的方案，通过部署一个安全的、沙箱化的内核代理直接实现在内核空间下的包过滤(Packet Filter)，尽早地将非目标网络包剔除，只对真正有效的目标网络包实施拷贝。&lt;/p&gt;
&lt;p&gt;BPF 最早于 1992 年被提出，1997 年起也被 Linux 内核吸收，定名 LSF (Linux Socket Filter, (aka) BPF:)。早期作用仅仅停留在过滤网络报文；在 2013 年由大牛 Alexei Starovoitov 彻底改造形成全新的 eBPF，并开始面向内核跟踪与事件监控、网络编程两大领域展示其强大的功能。&lt;/p&gt;
&lt;p&gt;本篇只着眼于传统的 BPF 技术，探求 BPF 如何在内核埋入包过滤相关的钩子以实现其功能。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>